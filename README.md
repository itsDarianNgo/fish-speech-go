# ğŸŸ Fish-Speech-Go

A high-performance, OpenAI-compatible API server for [Fish-Speech](https://github.com/fishaudio/fish-speech) text-to-speech.

**Run state-of-the-art TTS locally with a familiar API.**

[![Go Version](https://img.shields.io/badge/Go-1.21+-00ADD8?style=flat&logo=go)](https://go.dev)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat&logo=docker)](docker/)

## âœ¨ Why Fish-Speech-Go?

| Feature | OpenAI TTS | Fish-Speech-Go |
|---------|-----------|----------------|
| **Cost** | $15/1M characters | Free (self-hosted) |
| **Privacy** | Data sent to cloud | 100% local |
| **Rate Limits** | Yes | No |
| **Offline** | No | Yes |
| **Voice Cloning** | No | Yes |
| **API Compatibility** | - | OpenAI-compatible |

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- NVIDIA GPU with CUDA support
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
- Hugging Face account (free)

### 1. Clone & Configure

```bash
git clone https://github.com/fish-speech-go/fish-speech-go.git
cd fish-speech-go/docker
cp .env.example .env
```

Edit `.env` and add your Hugging Face token:
```env
HF_TOKEN=hf_your_token_here
```

> ğŸ“ **Get your token:** https://huggingface.co/settings/tokens
>
> âš ï¸ **Accept the license:** https://huggingface.co/fishaudio/openaudio-s1-mini

### 2. Start Services

```bash
docker compose up -d
```

First run downloads models (~2GB) - takes a few minutes.

### 3. Verify

```bash
curl http://localhost:8080/v1/health
```

## ğŸ“– API Reference

### OpenAI-Compatible Endpoints

#### Generate Speech

```bash
# POST /v1/audio/speech
curl -X POST http://localhost:8080/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{
    "model": "fish-speech",
    "voice": "default",
    "input": "Hello, world!"
  }' \
  --output speech.wav
```

#### Alternative TTS Endpoint

```bash
# POST /v1/tts
curl -X POST http://localhost:8080/v1/tts \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello, world!"}' \
  --output speech.wav
```

#### Health Check

```bash
# GET /v1/health
curl http://localhost:8080/v1/health
# Response: {"status": "ok"}
```

#### List Voices

```bash
# GET /v1/audio/voices
curl http://localhost:8080/v1/audio/voices
```

### Request Parameters

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `input` / `text` | string | Text to convert to speech | required |
| `model` | string | Model name | `fish-speech` |
| `voice` | string | Voice ID | `default` |
| `response_format` | string | Output format (wav, mp3) | `wav` |

## ğŸ”§ Integration Examples

### Python (OpenAI SDK)

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8080/v1",
    api_key="not-needed"  # Required by SDK but not validated
)

response = client.audio.speech.create(
    model="fish-speech",
    voice="default",
    input="Hello from Python!"
)

response.stream_to_file("output.mp3")
```

### JavaScript/TypeScript

```typescript
import OpenAI from 'openai';
import fs from 'fs';

const client = new OpenAI({
  baseURL: 'http://localhost:8080/v1',
  apiKey: 'not-needed',
});

const response = await client.audio.speech.create({
  model: 'fish-speech',
  voice: 'default',
  input: 'Hello from JavaScript!',
});

const buffer = Buffer.from(await response.arrayBuffer());
fs.writeFileSync('output.mp3', buffer);
```

### Go

```go
package main

import (
    "bytes"
    "encoding/json"
    "io"
    "net/http"
    "os"
)

func main() {
    payload := map[string]string{
        "input": "Hello from Go!",
        "model": "fish-speech",
        "voice": "default",
    }
    body, _ := json.Marshal(payload)

    resp, _ := http.Post(
        "http://localhost:8080/v1/audio/speech",
        "application/json",
        bytes.NewReader(body),
    )
    defer resp.Body.Close()

    out, _ := os.Create("output.wav")
    defer out.Close()
    io.Copy(out, resp.Body)
}
```

### cURL

```bash
curl -X POST http://localhost:8080/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{
    "model": "fish-speech",
    "voice": "default",
    "input": "Hello from the command line!"
  }' \
  --output speech.mp3
```

## âš™ï¸ Configuration

Configure via environment variables in `docker/.env`:

| Variable | Description | Default |
|----------|-------------|---------|
| `HF_TOKEN` | Hugging Face API token | **required** |
| `SERVER_PORT` | Go server port | `8080` |
| `API_KEY` | Optional API key for authentication | (none) |
| `LOG_LEVEL` | Log level: debug, info, warn, error | `info` |
| `LOG_FORMAT` | Log format: json, text | `json` |
| `MAX_TEXT_LENGTH` | Max input length (0 = unlimited) | `0` |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your App       â”‚â”€â”€â”€â”€â–¶â”‚   Go Server      â”‚â”€â”€â”€â”€â–¶â”‚   Fish-Speech    â”‚
â”‚   (Client)       â”‚â—€â”€â”€â”€â”€â”‚   (Port 8080)    â”‚â—€â”€â”€â”€â”€â”‚   (Port 8081)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      HTTP/JSON            Fast API Layer           ML Inference
                           OpenAI-Compatible        GPU (CUDA)
```

**Why this design?**
- **Go** handles HTTP, routing, validation, auth, logging (what Go does best)
- **Python** handles ML inference, GPU operations (what Python does best)
- **Result:** Fast, scalable, production-ready TTS

## ğŸ“ Project Structure

```
fish-speech-go/
â”œâ”€â”€ go/                      # Go API server
â”‚   â”œâ”€â”€ cmd/fish-server/     # Main entrypoint
â”‚   â”œâ”€â”€ cmd/fish-tts/        # CLI client for TTS
â”‚   â”œâ”€â”€ cmd/fish-ctl/        # Management CLI
â”‚   â”œâ”€â”€ internal/            # Core packages (api, backend, config, schema)
â”‚   â””â”€â”€ go.mod
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.server    # Go server image
â”‚   â”œâ”€â”€ Dockerfile.inference # Fish-Speech image
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ .env.example         # Example configuration
â”‚   â””â”€â”€ .env                 # Your local config (gitignored)
â”œâ”€â”€ docs/                    # Additional documentation
â”œâ”€â”€ scripts/                 # Helper scripts
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ› ï¸ Development

### Run Go Tests

```bash
cd go
go test ./...
```

### Build Go Binary

```bash
cd go
go build -o bin/server ./cmd/fish-server
```

### Build Docker Images

```bash
cd docker
docker compose build
```

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- [Fish-Speech](https://github.com/fishaudio/fish-speech) - The amazing TTS model
- [fishaudio](https://github.com/fishaudio) - Model creators

**â­ Star this repo if you find it useful!**
